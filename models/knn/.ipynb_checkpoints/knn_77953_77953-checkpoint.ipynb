{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN MODELS FOR 77,953:77,953 RATIO\n",
    "> **Undersampling the incative class and oversampling the active class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the big three\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# training algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# resampling algorithms\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# importing other libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# importing metrics \n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset into dataframe\n",
    "df = pd.read_csv(\"../../data/final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking dimension of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide dataframe into features, X and target y\n",
    "X = df.drop(['Activity'],axis=1)\n",
    "y = df['Activity']\n",
    "\n",
    "# checking class distribution\n",
    "print(y.value_counts())\n",
    "\n",
    "# visualizing class distribution\n",
    "ax = y.value_counts().plot(kind = 'pie', autopct = '%.3f')\n",
    "ax.set_title(\"Distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIVIDING INTO TRAIN AND TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing datasets into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# checking dimensions of train and test dataset\n",
    "print(\"The training and test data have the following dimensions:\\n{}{}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "# checking class distribution of train dataset\n",
    "print(\"The class distribution of the train data:\\n{}\".format(y_train.value_counts()))\n",
    "\n",
    "# visualizing class distribution of train dataset\n",
    "ax = y_train.value_counts().plot(kind = 'pie', autopct = '%.3f')\n",
    "ax.set_title(\"Training Set Distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SCALING\n",
    "> MinMaxScalar is a feature scaling algorithm that is will be used to scale all features of the dataset so they have similar range. This is expected to improve performance of the model\n",
    ">\n",
    "> Feature scaling is not needed hence it will not be done for all models. If it won't be done, skip this sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScalar will be used to scale the data\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# fit the scalar to the train set, it will learn the parameters\n",
    "mm.fit(X_train)\n",
    "\n",
    "# transform train and test sets\n",
    "X_train_mm = mm.transform(X_train)\n",
    "X_test_mm = mm.transform(X_test)\n",
    "\n",
    "# the transform function does not return a dataset so it is transformed into a dataframe\n",
    "X_train= pd.DataFrame(X_train_mm, columns = X_train.columns)\n",
    "X_test= pd.DataFrame(X_test_mm, columns=X_test.columns)\n",
    "\n",
    "# checking the shape of the new dataframes\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the dataframes after applying MinMaxScalar scalar should be the same as before it was applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  REMOVING LOW VARIANCE FEATURES\n",
    "> The variance threshold function will remove columns that dont meet a certain threshold. This is done to improve model performance\n",
    ">\n",
    "> There are two different thresholds for this. Use the second one only when MinMaxScalar was used. You can use only one threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vt = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "vt = VarianceThreshold(threshold=0.003) # Use this threshold instead when MinMaxScalar is used\n",
    "\n",
    "# Fit\n",
    "_ = vt.fit(X_train)\n",
    "\n",
    "# Get the mask\n",
    "mask = vt.get_support()\n",
    "\n",
    "# Subset the DataFrame\n",
    "X_train = X_train.loc[:, mask]\n",
    "X_test = X_test.loc[:, mask]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The number of rows in the dataset remain the same however the number of columns have reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN MODEL TRAINING\n",
    "> For this section, the model is trained on either unsampled data or resampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESAMPLING USING RUS AND SMOTE\n",
    "> The dataset is resampled using either one or a combination of random undersampler and smote with different ratios. Meaning, you can use undersampling and skip oversampling or vice versa or use both\n",
    ">\n",
    "> **THIS STEP SHOULD BE SKIPPED IF NO RESAMPLING WILL BE DONE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.5)\n",
    "X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "\n",
    "# checking class distribution on resampled dataset\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=1)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# checking class distribution of further resampled dataset\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing distribution of final resampled dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking class distribution of further resampled dataset\n",
    "print(y_train.value_counts())\n",
    "\n",
    "ax = y_train.value_counts().plot(kind = 'pie', autopct = '%.3f')\n",
    "ax.set_title(\"Distribution of classes in Resampled Data\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model object\n",
    "knn = KNeighborsClassifier(n_neighbors = 10, n_jobs = -1)\n",
    "\n",
    "# training model\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on train dataset\n",
    "train_predictions = knn.predict(X_train)    \n",
    "\n",
    "# predicting on test dataset\n",
    "test_predictions = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If the performance of the model on the training dataset is significantly better than the performance on the test dataset, then the model may have overfit the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECKING METRICS\n",
    "> The metrics will be checked for both the training data and the tes dataset\n",
    ">\n",
    "> For the confusion matrix: <br>\n",
    "> True Negative (Top-Left Quadrant)<br>\n",
    "False Positive (Top-Right Quadrant)<br>\n",
    "False Negative (Bottom-Left Quadrant)<br>\n",
    "True Positive (Bottom-Right Quadrant)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_test = accuracy_score(y_train, train_predictions)\n",
    "precision = precision_score(y_train, train_predictions)\n",
    "recall = recall_score(y_train, train_predictions)\n",
    "f1 = f1_score(y_train, train_predictions)\n",
    "mcc = matthews_corrcoef(y_train, train_predictions)\n",
    "\n",
    "pred_prob = knn.predict_proba(X_train)[:,1]\n",
    "auroc = roc_auc_score(y_train, pred_prob)                   \n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_test)\n",
    "print(\"Precision Score: \", precision)\n",
    "print(\"Recall Score: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"MCC: \", mcc)\n",
    "print(\"AUROC: \", auroc)\n",
    "\n",
    "cm = confusion_matrix(y_train, train_predictions)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = accuracy_score(y_test, test_predictions)\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "mcc = matthews_corrcoef(y_test, test_predictions)\n",
    "\n",
    "pred_prob = knn.predict_proba(X_test)\n",
    "auroc = roc_auc_score(y_test, pred_prob[:,1])\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_test)\n",
    "print(\"Precision Score: \", precision)\n",
    "print(\"Recall Score: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"MCC: \", mcc)\n",
    "print(\"AUROC: \", auroc)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLOTTING THE AUROC CURVE\n",
    "> This is done for only the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, pred_prob[:, 1])\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize = (5, 5), dpi = 100)\n",
    "plt.plot(fpr, tpr, label = 'XGBoost (auc = {})' .format(auc_score))\n",
    "plt.xlabel('False Positve Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Is the curve consistent to the auroc value obtained previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from numpy import mean\n",
    "\n",
    "# scores = cross_val_score(knn, X, y, scoring = 'roc_auc', cv = 2)\n",
    "# print('Mean ROC AUC: %.5f' % mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0c3bd7c9556569dc1ef9443ec91d3b9c536ca2b41c586f54944571d5f995c32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
